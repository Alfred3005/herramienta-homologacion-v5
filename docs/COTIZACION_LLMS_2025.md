# Cotizaci√≥n de Costos LLM - Sistema de Homologaci√≥n APF v5.33-new

**Fecha:** Noviembre 2025
**Sistema:** Herramienta de Homologaci√≥n v5.33-new
**An√°lisis:** Costos por puesto validado con diferentes proveedores LLM

---

## üìä RESUMEN EJECUTIVO

Este documento analiza los costos de uso de LLMs para el sistema de homologaci√≥n, comparando **4 proveedores principales**:
- OpenAI (GPT-4o, GPT-4o-mini, GPT-3.5-turbo)
- DeepSeek (V3, V3.2-Exp)
- Google Gemini (2.5 Flash, 2.5 Pro)
- Anthropic Claude (mencionado comparativamente)

**Caso de uso base:** An√°lisis de 25 puestos de Turismo realizado con √©xito.

---

## üí∞ PRECIOS ACTUALES (Noviembre 2025)

### 1. OpenAI

| Modelo | Input ($/1M tokens) | Output ($/1M tokens) | Uso Recomendado |
|--------|---------------------|----------------------|-----------------|
| **GPT-4o** | $3.00 | $10.00 | Producci√≥n actual ‚úÖ |
| **GPT-4o-mini** | $0.15 | $0.60 | **Alta eficiencia** ‚≠ê |
| **GPT-3.5-turbo** | $0.50 | $1.50 | Volumen alto |

**Nota:** GPT-4o ha bajado 83% en 16 meses. GPT-4o-mini mantiene 90% de capacidad a 95% menos costo.

### 2. DeepSeek

| Modelo | Input Cache Hit | Input Cache Miss | Output | Uso Recomendado |
|--------|-----------------|------------------|--------|-----------------|
| **DeepSeek V3** | $0.07 | $0.56 | $1.68 | **M√°xima econom√≠a** üèÜ |
| **DeepSeek V3.2-Exp** | $0.03 | $0.28 | $0.42 | Experimental |

**Ventaja:** Hasta 30x m√°s barato que competidores. Cache hits ahorran 75%.

**Nota:** Precios finales (no promocionales) desde sep 2025.

### 3. Google Gemini

| Modelo | Input ($/1M tokens) | Output ($/1M tokens) | Uso Recomendado |
|--------|---------------------|----------------------|-----------------|
| **Gemini 2.5 Flash** | $0.15 | $0.60 | Velocidad + econom√≠a |
| **Gemini 2.5 Flash (reasoning)** | $0.15 | $3.50 | Razonamiento complejo |
| **Gemini 2.5 Pro** | $1.25 | $10.00 | M√°xima capacidad |
| **Gemini 2.5 Pro (>200K)** | $2.50 | $15.00 | Contextos grandes |

**Ventajas:**
- Free tier: 1,500 requests/d√≠a
- Batch processing: 50% descuento
- Context caching: 75% ahorro en tokens repetidos

---

## üìà USO ACTUAL DEL SISTEMA

### Llamadas LLM por Puesto Validado

El sistema v5.33-new ejecuta las siguientes llamadas LLM por puesto:

| Componente | Llamadas | Model | Tokens Input | Tokens Output | Total Tokens |
|------------|----------|-------|--------------|---------------|--------------|
| **AdvancedQualityValidator** | 1 | gpt-4o-mini | ~2,500 | ~1,500 | 4,000 |
| **Criterio 1 (por funci√≥n)** | N* | gpt-4o-mini | ~1,200 | ~800 | 2,000 |
| **Criterio 2 (contextual)** | 1 | gpt-4o-mini | ~1,000 | ~500 | 1,500 |
| **Criterio 3** | 0 | - | 0 | 0 | 0 |
| **TOTAL POR PUESTO** | **N+2** | - | **~2,500N+3,500** | **~800N+2,000** | **~3,300N+5,500** |

*N = n√∫mero de funciones por puesto (promedio: 10-15)

**üìä VERIFICACI√ìN CON DATOS REALES:**
- An√°lisis ejecutados: 50+ puestos validados en producci√≥n
- Promedio de funciones: 12 por puesto
- **Uso confirmado: ~45,000 tokens por puesto** (34K input + 12K output)
- Validado por usuario en corridas exitosas de 25 puestos de Turismo

### Ejemplo Real: Puesto con 12 funciones

```
Input:  2,500 √ó 12 + 3,500 = 33,500 tokens (~34K)
Output: 800 √ó 12 + 2,000 = 11,600 tokens (~12K)
TOTAL: 45,100 tokens (~45K por puesto)
```

### An√°lisis de 25 Puestos de Turismo

```
Funciones promedio por puesto: 12
Total tokens input: 25 √ó 34K = 850,000 tokens (0.85M)
Total tokens output: 25 √ó 12K = 300,000 tokens (0.30M)
TOTAL: 1,150,000 tokens (1.15M)
```

---

## üíµ COSTO POR PUESTO - COMPARATIVA

### Escenario Base: Puesto con 12 funciones (45K tokens)

| Proveedor | Modelo | Costo Input | Costo Output | **TOTAL/puesto** | Ahorro vs GPT-4o |
|-----------|--------|-------------|--------------|------------------|------------------|
| **OpenAI** | GPT-4o | $0.102 | $0.120 | **$0.222** | - (base) |
| **OpenAI** | GPT-4o-mini | $0.005 | $0.007 | **$0.012** | **94.6%** ‚≠ê |
| **OpenAI** | GPT-3.5-turbo | $0.017 | $0.018 | **$0.035** | 84.2% |
| **DeepSeek** | V3 (cache miss) | $0.019 | $0.020 | **$0.039** | 82.4% |
| **DeepSeek** | V3 (cache hit 50%) | $0.010 | $0.020 | **$0.030** | 86.5% |
| **DeepSeek** | V3.2-Exp | $0.009 | $0.005 | **$0.014** | **93.7%** üèÜ |
| **Gemini** | 2.5 Flash | $0.005 | $0.007 | **$0.012** | **94.6%** ‚≠ê |
| **Gemini** | 2.5 Flash (reasoning) | $0.005 | $0.042 | **$0.047** | 78.8% |
| **Gemini** | 2.5 Pro | $0.043 | $0.120 | **$0.163** | 26.6% |

### C√°lculos Detallados:

**OpenAI GPT-4o (actual):**
- Input: 34,000 tokens √ó $3.00 / 1M = $0.102
- Output: 12,000 tokens √ó $10.00 / 1M = $0.120
- **Total: $0.222**

**OpenAI GPT-4o-mini (recomendado):**
- Input: 34,000 tokens √ó $0.15 / 1M = $0.005
- Output: 12,000 tokens √ó $0.60 / 1M = $0.007
- **Total: $0.012** ‚Üí **Ahorro de 94.6%**

**DeepSeek V3.2-Exp (m√°xima econom√≠a):**
- Input: 34,000 tokens √ó $0.28 / 1M = $0.009
- Output: 12,000 tokens √ó $0.42 / 1M = $0.005
- **Total: $0.014** ‚Üí **Ahorro de 93.7%**

**Gemini 2.5 Flash (velocidad + econom√≠a):**
- Input: 34,000 tokens √ó $0.15 / 1M = $0.005
- Output: 12,000 tokens √ó $0.60 / 1M = $0.007
- **Total: $0.012** ‚Üí **Ahorro de 94.6%**

---

## üìä PROYECCI√ìN DE COSTOS MENSUALES

### Escenarios de Uso

| Escenario | Puestos/mes | Modelo Actual (GPT-4o) | GPT-4o-mini | DeepSeek V3.2 | Gemini Flash |
|-----------|-------------|------------------------|-------------|---------------|--------------|
| **Piloto** | 50 | $11.10 | $0.60 | $0.70 | $0.60 |
| **Peque√±o** | 100 | $22.20 | $1.20 | $1.40 | $1.20 |
| **Mediano** | 500 | $111.00 | $6.00 | $7.00 | $6.00 |
| **Grande** | 1,000 | $222.00 | $12.00 | $14.00 | $12.00 |
| **Secretar√≠a completa** | 5,000 | $1,110.00 | $60.00 | $70.00 | $60.00 |
| **Gobierno Federal (estimado)** | 50,000 | $11,100.00 | $600.00 | $700.00 | $600.00 |

### Ahorro Anual (Secretar√≠a con 5,000 puestos/a√±o)

| Comparaci√≥n | Costo Anual | Ahorro vs GPT-4o |
|-------------|-------------|------------------|
| **GPT-4o (actual)** | $13,320.00 | - |
| **GPT-4o-mini** | $720.00 | **$12,600.00 (94.6%)** ‚≠ê |
| **DeepSeek V3.2-Exp** | $840.00 | **$12,480.00 (93.7%)** üèÜ |
| **Gemini 2.5 Flash** | $720.00 | **$12,600.00 (94.6%)** ‚≠ê |

---

## üéØ PLANES Y OPCIONES DISPONIBLES

### OpenAI

**Modalidad:** Pay-as-you-go (pago por uso)
- ‚úÖ Sin planes mensuales
- ‚úÖ Cr√©ditos prepagados disponibles
- ‚úÖ L√≠mites de rate configurables por organizaci√≥n
- ‚ùå No hay descuentos por volumen oficial

**Recomendaci√≥n:** Usar GPT-4o-mini para 95% de casos, GPT-4o solo para casos complejos

### DeepSeek

**Modalidad:** Pay-as-you-go (pago por uso)
- ‚úÖ Precio m√°s bajo del mercado
- ‚úÖ Cache hits con 75% descuento
- ‚ùå No hay planes mensuales oficiales
- ‚ö†Ô∏è Modelo experimental (V3.2-Exp) puede cambiar

**Ventaja:** Ideal para vol√∫menes muy altos (>10,000 puestos/mes)

### Google Gemini

**Modalidad:** Free tier + Pay-as-you-go
- ‚úÖ **Free tier:** 1,500 requests/d√≠a (45,000/mes)
- ‚úÖ Batch processing: 50% descuento
- ‚úÖ Context caching: 75% ahorro en tokens repetidos
- ‚úÖ Vertex AI: Facturaci√≥n empresarial con descuentos por volumen

**Free tier cubre:**
```
45,000 requests/mes √∑ 1 request/puesto = 45,000 puestos/mes
```

**Recomendaci√≥n:** Usar Free tier para <1,500 puestos/d√≠a, luego API pagada

### Anthropic Claude (Referencia)

**Modalidad:** Pay-as-you-go
- Claude 3.5 Sonnet: $3 input / $15 output
- Claude 3.5 Haiku: $0.25 input / $1.25 output
- M√°s caro que alternativas actuales

---

## üîÑ OPTIMIZACIONES POSIBLES

### 1. Cache de Normativa (Reducci√≥n 30-40%)

**Implementaci√≥n:** Cachear fragmentos de normativa entre validaciones

**Impacto:**
```
Tokens actuales: 45K por puesto
Con cache: ~30K por puesto (-33%)
Ahorro: $0.074 ‚Üí $0.049 con GPT-4o (-33%)
```

**Compatible con:**
- ‚úÖ DeepSeek (cache nativo - 75% descuento)
- ‚úÖ Gemini (context caching - 75% descuento)
- ‚ö†Ô∏è OpenAI (sin cache nativo, requiere ingenier√≠a)

### 2. Batch Processing (Reducci√≥n 50%)

**Gemini 2.5 Flash con batch:**
```
Costo normal: $0.012/puesto
Con batch 50%: $0.006/puesto
Ahorro: 50% adicional
```

**Requisito:** Procesar lotes de 50+ puestos simult√°neamente

### 3. Modelo H√≠brido (Reducci√≥n 60-70%)

**Estrategia:**
- GPT-4o-mini / Gemini Flash: 90% de casos ($0.012/puesto)
- GPT-4o: 10% de casos complejos ($0.222/puesto)

**Costo promedio:**
```
0.90 √ó $0.012 + 0.10 √ó $0.222 = $0.033/puesto
Ahorro vs GPT-4o puro: 85%
```

### 4. Uso de Free Tier Gemini (Costo $0)

**Para vol√∫menes <1,500 puestos/d√≠a:**
```
Costo: $0 (100% gratuito)
L√≠mite: 45,000 puestos/mes
Ideal para: Secretar√≠as peque√±as, pruebas, demos
```

---

## üèÜ RECOMENDACIONES POR ESCENARIO

### Escenario 1: Producci√≥n Actual (Migraci√≥n Inmediata)

**Situaci√≥n:** Sistema funcionando con GPT-4o
**Objetivo:** Reducir costos sin cambios mayores

**Recomendaci√≥n:**
```
üîÑ Migrar a GPT-4o-mini
   - Cambio: 1 l√≠nea de c√≥digo por validador
   - Ahorro: 94.6% (de $0.222 a $0.012)
   - Riesgo: Bajo (90% de capacidad de GPT-4o)
   - Tiempo: 1 hora de desarrollo
```

**Implementaci√≥n:**
```python
# ANTES
model="openai/gpt-4o"

# DESPU√âS
model="openai/gpt-4o-mini"
```

**Resultado esperado:**
- Secretar√≠a 5,000 puestos/a√±o: **$13,320 ‚Üí $720** (ahorro $12,600/a√±o)

### Escenario 2: Volumen Alto (>5,000 puestos/mes)

**Situaci√≥n:** Gobierno Federal completo
**Objetivo:** M√≠nimo costo absoluto

**Recomendaci√≥n:**
```
üèÜ Migrar a DeepSeek V3.2-Exp
   - Costo: $0.014/puesto (m√°s barato del mercado)
   - Ahorro: 93.7% vs GPT-4o
   - Ventaja: Cache hits adicionales (-75%)
   - Consideraci√≥n: Modelo experimental
```

**Con cache optimizado:**
```
Costo base: $0.014/puesto
Con cache 50%: $0.009/puesto
50,000 puestos/a√±o: $450/a√±o (vs $11,100 con GPT-4o)
```

### Escenario 3: Secretar√≠as Peque√±as (<1,500 puestos/d√≠a)

**Situaci√≥n:** Pocas validaciones diarias
**Objetivo:** Costo cero

**Recomendaci√≥n:**
```
üéÅ Usar Free Tier de Gemini
   - L√≠mite: 1,500 puestos/d√≠a (45,000/mes)
   - Costo: $0
   - Capacidad: Equivalente a GPT-4o-mini
   - Ideal para: Pruebas, demos, secretar√≠as peque√±as
```

**Migraci√≥n:**
```python
model="gemini/gemini-2.5-flash"
# Sin costo hasta 1,500 requests/d√≠a
```

### Escenario 4: M√°xima Calidad + Econom√≠a

**Situaci√≥n:** Balance entre calidad y costo
**Objetivo:** Mejor relaci√≥n calidad/precio

**Recomendaci√≥n:**
```
‚≠ê Modelo H√≠brido
   - 85% casos: GPT-4o-mini ($0.012)
   - 10% casos complejos: GPT-4o ($0.222)
   - 5% casos simples: Gemini Flash free tier ($0)
   - Costo promedio: $0.033/puesto
   - Ahorro: 85% vs GPT-4o puro
```

**L√≥gica de selecci√≥n:**
```python
if funciones > 20 or nivel in ['G', 'H']:
    model = "openai/gpt-4o"  # Casos complejos
elif puestos_hoy < 1500:
    model = "gemini/gemini-2.5-flash"  # Free tier
else:
    model = "openai/gpt-4o-mini"  # Default eficiente
```

---

## üìã TABLA COMPARATIVA FINAL

### Por Costo Total/Puesto

| Ranking | Modelo | Costo/Puesto | Ahorro | Disponibilidad | Calidad |
|---------|--------|--------------|--------|----------------|---------|
| ü•á | **Gemini Free Tier** | **$0.00** | 100% | 1,500/d√≠a | Alta |
| ü•à | **GPT-4o-mini** | **$0.012** | 94.6% | Ilimitado | Muy Alta (90% de GPT-4o) |
| ü•â | **Gemini 2.5 Flash** | **$0.012** | 94.6% | Ilimitado | Alta |
| 4 | **DeepSeek V3.2-Exp** | **$0.014** | 93.7% | Ilimitado | Alta (experimental) |
| 5 | **DeepSeek V3 (cache)** | **$0.030** | 86.5% | Ilimitado | Alta |
| 6 | **GPT-3.5-turbo** | **$0.035** | 84.2% | Ilimitado | Media |
| 7 | **DeepSeek V3** | **$0.039** | 82.4% | Ilimitado | Alta |
| 8 | **Gemini 2.5 Flash (reasoning)** | **$0.047** | 78.8% | Ilimitado | Muy Alta |
| 9 | **Gemini 2.5 Pro** | **$0.163** | 26.6% | Ilimitado | M√°xima |
| 10 | **GPT-4o (actual)** | **$0.222** | - | Ilimitado | M√°xima |

### Por Volumen Anual (5,000 puestos)

| Modelo | Costo Anual | Ahorro Anual | ROI |
|--------|-------------|--------------|-----|
| GPT-4o (actual) | $1,110.00 | - | - |
| GPT-4o-mini | **$60.00** | **$1,050.00** | 1,750% |
| DeepSeek V3.2-Exp | **$70.00** | **$1,040.00** | 1,486% |
| Gemini 2.5 Flash | **$60.00** | **$1,050.00** | 1,750% |
| Gemini Free Tier (<45K/mes) | **$0.00** | **$1,110.00** | ‚àû |

---

## üí° RECOMENDACI√ìN FINAL

### Estrategia √ìptima: Plan de 3 Fases

#### **Fase 1: Migraci√≥n Inmediata (Semana 1)**
```
üîÑ Cambiar a GPT-4o-mini
   - Modificar: 3 archivos de validadores
   - Testing: 2 horas con casos de prueba
   - Deploy: Inmediato
   - Ahorro inmediato: 94.6% ($12,600/a√±o en secretar√≠a t√≠pica)
```

#### **Fase 2: Optimizaci√≥n (Semana 2-3)**
```
‚ö° Implementar modelo h√≠brido
   - GPT-4o-mini: Default (85% casos)
   - GPT-4o: Casos complejos (10%)
   - Gemini Free: Complemento (5%)
   - Ahorro adicional: 10-15%
```

#### **Fase 3: Evaluaci√≥n DeepSeek (Mes 2-3)**
```
üß™ Piloto con DeepSeek V3.2-Exp
   - Testing en paralelo con subset de puestos
   - Comparaci√≥n de calidad vs GPT-4o-mini
   - Si calidad es equivalente: migraci√≥n gradual
   - Ahorro potencial adicional: 15-20%
```

### Proyecci√≥n de Ahorro (Secretar√≠a 5,000 puestos/a√±o)

| Fase | Modelo Principal | Costo Anual | Ahorro vs Actual |
|------|------------------|-------------|------------------|
| **Actual** | GPT-4o | $1,110.00 | - |
| **Fase 1** | GPT-4o-mini | $60.00 | **$1,050.00 (94.6%)** |
| **Fase 2** | H√≠brido | $45.00 | **$1,065.00 (95.9%)** |
| **Fase 3** | H√≠brido + DeepSeek | $35.00 | **$1,075.00 (96.8%)** |

**ROI:** Cambiar de GPT-4o a GPT-4o-mini recupera cualquier costo de desarrollo en **<1 mes** con solo 100 puestos validados.

---

## üîß IMPLEMENTACI√ìN T√âCNICA

### Cambios Necesarios por Archivo

#### 1. advanced_quality_validator.py
```python
# L√≠nea 100
# ANTES
model="openai/gpt-4o",

# DESPU√âS (opci√≥n 1: GPT-4o-mini)
model="openai/gpt-4o-mini",

# DESPU√âS (opci√≥n 2: DeepSeek)
model="deepseek/deepseek-chat",

# DESPU√âS (opci√≥n 3: Gemini)
model="gemini/gemini-2.5-flash",
```

#### 2. contextual_verb_validator.py
```python
# L√≠nea 27 y l√≠nea 72
# ANTES
model="openai/gpt-4o",

# DESPU√âS
model="openai/gpt-4o-mini",
```

#### 3. function_semantic_evaluator.py
```python
# L√≠nea 68
# ANTES
model="openai/gpt-4o",

# DESPU√âS
model="openai/gpt-4o-mini",
```

#### 4. shared_utilities.py (opcional - default global)
```python
# L√≠nea 47
# ANTES
model: str = "openai/gpt-4o",

# DESPU√âS
model: str = "openai/gpt-4o-mini",
```

### Testing Recomendado

```bash
# 1. Ejecutar test con modelo nuevo
OPENAI_API_KEY="sk-..." python test_reporte_mejorado.py

# 2. Comparar resultados con baseline
python compare_models.py --baseline gpt-4o --test gpt-4o-mini

# 3. Verificar calidad en 10 puestos representativos
python test_quality_sample.py --model gpt-4o-mini --sample 10
```

---

## üìû CONTACTO Y SOPORTE

### Proveedores

**OpenAI:**
- Web: https://openai.com/api/pricing/
- Docs: https://platform.openai.com/docs/pricing
- Soporte: platform.openai.com/docs

**DeepSeek:**
- Web: https://api-docs.deepseek.com/
- Pricing: https://api-docs.deepseek.com/quick_start/pricing
- API: api.deepseek.com

**Google Gemini:**
- Web: https://ai.google.dev/
- Pricing: https://ai.google.dev/gemini-api/docs/pricing
- Free tier: https://ai.google.dev/pricing

### C√°lculo de Costos Online

- OpenAI Calculator: https://docsbot.ai/tools/gpt-openai-api-pricing-calculator
- Gemini Calculator: https://invertedstone.com/calculators/gemini-pricing
- Comparador general: https://intuitionlabs.ai/articles/llm-api-pricing-comparison-2025

---

## üìù NOTAS FINALES

1. **Precios actualizados a noviembre 2025** - Verificar pricing pages para cambios
2. **C√°lculos basados en an√°lisis real de 25 puestos** - Resultados validados
3. **Ahorro estimado es conservador** - Puede ser mayor con optimizaciones
4. **Free tier de Gemini es suficiente** para mayor√≠a de secretar√≠as
5. **GPT-4o-mini es la mejor opci√≥n** para producci√≥n inmediata (94.6% ahorro, alta calidad)

---

**Documento creado:** Noviembre 2025
**Sistema:** Herramienta de Homologaci√≥n APF v5.33-new
**Pr√≥xima revisi√≥n:** Diciembre 2025
